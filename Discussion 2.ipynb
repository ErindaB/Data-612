{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA612 : Research Discussion Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Instructions\n",
    "For this discussion item, please watch the following talk and summarize what you found to be the most important or interesting points. The first half will cover some of the mathematical techniques covered in this unit’s reading and the second half some of the data management challenges in an industrial-scale recommendation system.\n",
    "\n",
    "Music Recommendations at Scale with Spark - Christopher Johnson (Spotify)\n",
    "https://www.youtube.com/watch?v=3LBgiFch4_g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "At the time of the video,(2014) Spotify was using Hadoop as a way to create song recommendations for users. With a decomposed matrix, Spotify sends components of the ratings matrix,  based on the ratings for each song, to separate nodes. Using Hadoop alone created a bottleneck where information had to be sent back and forth many times. The proposal for this  bottleneck was to utilize Spark, which loads the ratings matrix into memory and caches the data.Each node contains a cache of the matrices it needs to perform work. This is what makes the rating system faster than distributive computing using Hadoop alone. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to find good recommendations:\n",
    "1.Audio Content, Metadata, Text Analysis : Music data is analyzed from music blogs, twitter or music articles as is done by echonest, Spotify\n",
    "\n",
    "2.Manually Tag Attributes : Not scalable but music experts manually tag all of the catalog as being by done by Pandora’s music genome project\n",
    "\n",
    "3.Manual Curation : Not scalable but for smaller catalog it is good as being done by Songza and Beats\n",
    "\n",
    "4.Collaborative Filtering : Analyse music users are listening, finding relationships and recommending based on that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix’s Explicit Matrix Factorization\n",
    "Users explicitly rate a subset of movie catalog in order to predict how users will rate new movies\n",
    "\n",
    "Approximate ratings matrix by the product of low-dimensional user and movie matrices\n",
    "\n",
    "Minimize RMSE (root mean squared error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify’s Implicit Matrix Factorization\n",
    "Use of binary labels inferred implicitly based on what user’s are already listening to in order to  minimize a loss function\n",
    "\n",
    "1 = streamed at least once\n",
    "\n",
    "0 = never streamed \n",
    "\n",
    "\n",
    "\n",
    "Minimize weighted RMSE (root mean squared error) using a function of total streams as weights\n",
    "\n",
    "Derivatives are an obvious tool for minimizing functions, the two most popular derivative-based methods are:\n",
    "\n",
    "Alternating Least Squares (ALS)\n",
    "\n",
    "Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Random Learning\n",
    "PairRDDFunctions in Spark : Split data into Key-Value pairs and RDD functions can be joined using group by partition keys\n",
    "Kyro serialization faster than Java serialization but may require to write and/or register one’s own serializers\n",
    "kNN vs Matrix Factorization : kNN approach cannot compute similarity between user and item but can only compute similarity between user-user or item-item to give recommendations because kNN method does not deal really well with sparse matrices, as such matrices would work better with matrix decomposition algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The most interesting part for me was the use of Spark for im-memory data processing for more efficient and real-time calculations that are horizontally scalable.\n",
    "Hadoop and Spark facilitate the processing of large datasets however Hadoop utilizes disk space for storage during calculations while Spark utilizes system memory. The presentation seemed biased towards spark since the use of the system memory along with caching outperforms Hadoop I/O approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
